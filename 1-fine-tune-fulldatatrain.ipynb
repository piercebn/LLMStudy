{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ed13a0f-b059-49fc-be0b-fa284a5e96fa",
   "metadata": {},
   "source": [
    "基于 Transformers 实现模型微调训练的主要流程，包括：\n",
    "- 数据集下载\n",
    "- 数据预处理\n",
    "- 训练超参数配置\n",
    "- 训练评估指标设置\n",
    "- 实战训练\n",
    "- 模型保存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a772bede-949c-48b9-89af-736985ab14b4",
   "metadata": {},
   "source": [
    "1、数据集下载（包括训练集train和测试集test）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a7cabb4-1143-430a-a0a5-077c2d834dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 650000 examples [00:01, 579665.69 examples/s]\n",
      "Generating test split: 50000 examples [00:00, 543726.21 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"yelp_review_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc46a218-5987-4988-a378-24ed144aba2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 650000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5216b048-b1a7-45e2-bd03-d56d19f437d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 1,\n",
       " 'text': \"Unfortunately, the frustration of being Dr. Goldberg's patient is a repeat of the experience I've had with so many other doctors in NYC -- good doctor, terrible staff.  It seems that his staff simply never answers the phone.  It usually takes 2 hours of repeated calling to get an answer.  Who has time for that or wants to deal with it?  I have run into this problem with many other doctors and I just don't get it.  You have office workers, you have patients with medical needs, why isn't anyone answering the phone?  It's incomprehensible and not work the aggravation.  It's with regret that I feel that I have to give Dr. Goldberg 2 stars.\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf818c5e-0793-4aeb-baa0-59081630d653",
   "metadata": {},
   "source": [
    "2、数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03ad64ff-0ba5-4e49-a5e0-ab19520c3ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/650000 [00:00<?, ? examples/s]Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Map: 100%|██████████| 650000/650000 [01:49<00:00, 5933.79 examples/s]\n",
      "Map: 100%|██████████| 50000/50000 [00:08<00:00, 6025.95 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89ffa338-bece-4011-9c8d-4301f2a6c9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d652515a-3f54-4475-ac22-cdb0d736cb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a1369a3-5da3-4e81-980c-6c009e5883db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 star</td>\n",
       "      <td>Not a very good Wal Mart. The store is messy and dirty, as well as dimly lit in spots. I only encountered one employee and she was friendly enough, but it wasn't enough to save this place for me. Would steer clear if I were you.</td>\n",
       "      <td>[101, 1753, 170, 1304, 1363, 160, 1348, 24341, 119, 1109, 2984, 1110, 20549, 1105, 7320, 117, 1112, 1218, 1112, 12563, 1193, 4941, 1107, 7152, 119, 146, 1178, 8181, 1141, 7775, 1105, 1131, 1108, 4931, 1536, 117, 1133, 1122, 1445, 112, 189, 1536, 1106, 3277, 1142, 1282, 1111, 1143, 119, 5718, 25284, 2330, 1191, 146, 1127, 1128, 119, 102]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(tokenized_datasets[\"train\"], num_examples=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6dc615-bd9d-4ad3-925d-2deee09f07b1",
   "metadata": {},
   "source": [
    "3、数据抽样（全量）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd34f592-907a-45a7-b910-486864ac9706",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"]\n",
    "small_eval_dataset = tokenized_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a20dd8-0d7e-4a76-ab23-693f12812026",
   "metadata": {},
   "source": [
    "4、加载BERT模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82a27af5-56d5-4026-80e4-150a5717cfd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./models/bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae821b85-9f53-4926-b32f-feb39853d687",
   "metadata": {},
   "source": [
    "5、训练超参数配置（TrainingArguments）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9e17398-a111-4e77-9b6e-4b831324d617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/python311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "# 模型权重保存路径(output_dir)\n",
    "model_dir = \"./models/bert-base-cased-finetune-yelp\"\n",
    "\n",
    "# 为了监控训练过程中的评估指标变化，我们可以在TrainingArguments指定evaluation_strategy参数，以便在 epoch 结束时报告评估指标\n",
    "# logging_steps 默认值为500，根据我们的训练数据和步长，将其设置为100\n",
    "training_args = TrainingArguments(output_dir=model_dir,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  per_device_train_batch_size=16,\n",
    "                                  num_train_epochs=3,\n",
    "                                  logging_steps=100)\n",
    "\n",
    "# 完整的超参数配置\n",
    "print(training_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3ee283-51d9-493e-a2c9-91570d6c4fb8",
   "metadata": {},
   "source": [
    "6、"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa20230e-1f30-446d-a8bd-f74ad9cf6a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f73765f-10ea-49cd-be66-c55209395f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566aaf53-17bd-4e05-8b82-8cd2c404329d",
   "metadata": {},
   "source": [
    "7、实例化训练器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b351fe1-8e9d-48df-ae54-711f25760276",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb4e8ee-c6dd-46dc-9094-3c940b3ffdf2",
   "metadata": {},
   "source": [
    "8、进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20393c04-db6a-4a3b-96c4-50989e41dfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffea37b5-5351-459d-a3be-b11582a36ccb",
   "metadata": {},
   "source": [
    "9、训练后评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a1628c-7bcc-40d4-a70d-1c2274c7dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_test_dataset = tokenized_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43593246-b8b7-4523-912b-32b1bd022619",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(small_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd74566-3820-4373-b703-4fb3133e98f5",
   "metadata": {},
   "source": [
    "10、保存模型和训练状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825d45e8-2380-4695-9e65-9741e1bdfce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f554365a-3bdc-424b-b68a-11cfb0a5d378",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_state()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
